{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from ptflops import get_model_complexity_info\n",
    "from src import get_model\n",
    "import argparse\n",
    "from src.layers.KANLinear import KANLinear\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from src.layers.spline import *\n",
    "\n",
    "\n",
    "class KANLinear(nn.Module):\n",
    "    \"\"\"\n",
    "    KANLayer class\n",
    "    \n",
    "\n",
    "    Attributes:\n",
    "    -----------\n",
    "        in_dim: int\n",
    "            input dimension\n",
    "        out_dim: int\n",
    "            output dimension\n",
    "        num: int\n",
    "            the number of grid intervals\n",
    "        k: int\n",
    "            the piecewise polynomial order of splines\n",
    "        noise_scale: float\n",
    "            spline scale at initialization\n",
    "        coef: 2D torch.tensor\n",
    "            coefficients of B-spline bases\n",
    "        scale_base_mu: float\n",
    "            magnitude of the residual function b(x) is drawn from N(mu, sigma^2), mu = sigma_base_mu\n",
    "        scale_base_sigma: float\n",
    "            magnitude of the residual function b(x) is drawn from N(mu, sigma^2), mu = sigma_base_sigma\n",
    "        scale_sp: float\n",
    "            mangitude of the spline function spline(x)\n",
    "        base_activation: fun\n",
    "            residual function b(x)\n",
    "        grid_eps: float in [0,1]\n",
    "            a hyperparameter used in update_grid_from_samples. When grid_eps = 1, the grid is uniform; when grid_eps = 0, the grid is partitioned using percentiles of samples. 0 < grid_eps < 1 interpolates between the two extremes.\n",
    "            the id of activation functions that are locked\n",
    "        device: str\n",
    "            device\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, \n",
    "        in_dim=3,\n",
    "        out_dim=2,\n",
    "        num=5, \n",
    "        k=3, \n",
    "        noise_scale=0.5, \n",
    "        scale_base_mu=0.0, \n",
    "        scale_base_sigma=1.0, \n",
    "        scale_sp=1.0, \n",
    "        base_activation=torch.nn.SiLU(), \n",
    "        grid_eps=0.02, \n",
    "        grid_range=[-1, 1], \n",
    "        sp_trainable=True, \n",
    "        sb_trainable=True, \n",
    "        save_plot_data = True,\n",
    "        stochastic_variance = 0.1,\n",
    "        device='cpu', \n",
    "        neuron_fun=None,\n",
    "        noise_type=None\n",
    "        ):\n",
    "        ''''\n",
    "        initialize a KANLayer\n",
    "        \n",
    "        Args:\n",
    "        -----\n",
    "            in_dim : int\n",
    "                input dimension. Default: 2.\n",
    "            out_dim : int\n",
    "                output dimension. Default: 3.\n",
    "            num : int\n",
    "                the number of grid intervals = G. Default: 5.\n",
    "            k : int\n",
    "                the order of piecewise polynomial. Default: 3.\n",
    "            noise_scale : float\n",
    "                the scale of noise injected at initialization. Default: 0.5.\n",
    "            scale_base_mu : float\n",
    "                the scale of the residual function b(x) is intialized to be N(scale_base_mu, scale_base_sigma^2).\n",
    "            scale_base_sigma : float\n",
    "                the scale of the residual function b(x) is intialized to be N(scale_base_mu, scale_base_sigma^2).\n",
    "            scale_sp : float\n",
    "                the scale of the base function spline(x).\n",
    "            base_activation: function\n",
    "                residual function b(x). Default: torch.nn.SiLU()\n",
    "            grid_eps : float\n",
    "                When grid_eps = 1, the grid is uniform; when grid_eps = 0, the grid is partitioned using percentiles of samples. 0 < grid_eps < 1 interpolates between the two extremes.\n",
    "            grid_range : list/np.array of shape (2,)\n",
    "                setting the range of grids. Default: [-1,1].\n",
    "            sp_trainable : bool\n",
    "                If true, scale_sp is trainable\n",
    "            sb_trainable : bool\n",
    "                If true, scale_base is trainable\n",
    "            device : str\n",
    "                device\n",
    "            sparse_init : bool\n",
    "                if sparse_init = True, sparse initialization is applied.\n",
    "            \n",
    "        Returns:\n",
    "        --------\n",
    "            self\n",
    "            \n",
    "        Example\n",
    "        -------\n",
    "        >>> from kan.KANLayer import *\n",
    "        >>> model = KANLayer(in_dim=3, out_dim=5)\n",
    "        >>> (model.in_dim, model.out_dim)\n",
    "        '''\n",
    "        super(KANLinear, self).__init__()\n",
    "        print(f\"Noise type: {noise_type}\")\n",
    "        print(f\"Neuron fun: {neuron_fun}\")\n",
    "        print(f\"Out dim: : {out_dim}\")\n",
    "        print(f\"In dim:  {in_dim}\")\n",
    "        print(f\"Grid size:  {num}\")\n",
    "        print(f\"Spline order:  {k}\")\n",
    "\n",
    "        # size \n",
    "        self.out_dim = out_dim\n",
    "        self.in_dim = in_dim\n",
    "        self.num = num\n",
    "        self.k = k\n",
    "        print(f\"num: {num}, grid_range: {grid_range}\")\n",
    "\n",
    "        grid = torch.linspace(grid_range[0], grid_range[1], steps=num + 1)[None,:].expand(self.in_dim, num+1)\n",
    "\n",
    "        grid = extend_grid(grid, k_extend=k)\n",
    "\n",
    "        self.grid = torch.nn.Parameter(grid).requires_grad_(False)\n",
    "\n",
    "        noises = (torch.rand(self.num+1, self.in_dim, self.out_dim) - 1/2) * noise_scale / num\n",
    "\n",
    "        self.coef = torch.nn.Parameter(curve2coef(self.grid[:,k:-k].permute(1,0), noises, self.grid, k))\n",
    "        \n",
    "        self.scale_base = torch.nn.Parameter(scale_base_mu * 1 / np.sqrt(in_dim) + \\\n",
    "                         scale_base_sigma * (torch.rand(in_dim, out_dim)*2-1) * 1/np.sqrt(in_dim)).requires_grad_(sb_trainable)\n",
    "\n",
    "        self.scale_sp = torch.nn.Parameter(torch.ones(in_dim, out_dim) * scale_sp * 1 / np.sqrt(in_dim)).requires_grad_(sp_trainable)  # make scale trainable\n",
    "\n",
    "        self.base_activation = base_activation\n",
    "        \n",
    "        self.stochastic_variance = torch.nn.Parameter(torch.tensor(stochastic_variance)).requires_grad_(True)\n",
    "\n",
    "        self.neuron_fun = neuron_fun\n",
    "\n",
    "        self.grid_eps = grid_eps\n",
    "\n",
    "        self.noise_type = noise_type\n",
    "        print(f\"Noise type: {noise_type}\")\n",
    "        print(f\"Neuron fun: {neuron_fun}\")\n",
    "        print(f\"Out dim: : {out_dim}\")\n",
    "        print(f\"In dim:  {in_dim}\")\n",
    "        print(f\"Grid size:  {num}\")\n",
    "        print(f\"Spline order:  {k}\")\n",
    "\n",
    "\n",
    "        self.to(device)\n",
    "        \n",
    "    def to(self, device):\n",
    "        super(KANLinear, self).to(device)\n",
    "        self.device = device    \n",
    "        return self\n",
    "\n",
    "    def forward(self, x):\n",
    "        '''\n",
    "        KANLayer forward given input x\n",
    "        \n",
    "        Args:\n",
    "        -----\n",
    "            x : 2D torch.float\n",
    "                inputs, shape (number of samples, input dimension)\n",
    "            \n",
    "        Returns:\n",
    "        --------\n",
    "            y : 2D torch.float\n",
    "                outputs, shape (number of samples, output dimension)\n",
    "            preacts : 3D torch.float\n",
    "                fan out x into activations, shape (number of sampels, output dimension, input dimension)\n",
    "            postacts : 3D torch.float\n",
    "                the outputs of activation functions with preacts as inputs\n",
    "            postspline : 3D torch.float\n",
    "                the outputs of spline functions with preacts as inputs\n",
    "        \n",
    "        Example\n",
    "        -------\n",
    "        >>> from kan.KANLayer import *\n",
    "        >>> model = KANLayer(in_dim=3, out_dim=5)\n",
    "        >>> x = torch.normal(0,1,size=(100,3))\n",
    "        >>> y, preacts, postacts, postspline = model(x)\n",
    "        >>> y.shape, preacts.shape, postacts.shape, postspline.shape\n",
    "        '''\n",
    "        batch = x.shape[0]            \n",
    "        base = self.base_activation(x) # (batch, in_dim)\n",
    "        y = coef2curve(x_eval=x, grid=self.grid, coef=self.coef, k=self.k)\n",
    "        y = self.scale_base[None,:,:] * base[:,:,None] + self.scale_sp[None,:,:] * y\n",
    "        # print(f\"Shape of y before summation: {y.shape}\")  # Add this line\n",
    "        if self.neuron_fun == \"sum\":\n",
    "            y = torch.sum(y, dim=1)\n",
    "        elif self.neuron_fun == \"mean\":\n",
    "            y = torch.mean(y, dim=1)\n",
    "            \n",
    "        # if self.training:\n",
    "        #     # print(\"I'm training\")\n",
    "        #     if self.noise_type == \"uniform\":\n",
    "        #         y += (torch.rand_like(y) * 2 - 1 ) * self.stochastic_variance        # Uniform range [-1, 1)\n",
    "        #     elif self.noise_type == \"normal\":\n",
    "        #         y += torch.randn_like(y) * self.stochastic_variance                  # Normal distribution\n",
    "\n",
    "        return y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from timm.layers import trunc_normal_\n",
    "from src.layers.custom_layers import LayerNorm, PositionalEncodingFourier\n",
    "from src.layers.sdta_encoder import SDTAEncoder\n",
    "from src.layers.conv_encoder import ConvEncoder\n",
    "from src.layers.LoRaLin import LoRaLin\n",
    "# from src.layers.KANLinear import KANLinear\n",
    "\n",
    "class EdgeFaceKAN(nn.Module):\n",
    "    def __init__(self, in_chans=3, num_features=512, rank_ratio = 0.6,\n",
    "                 depths=[3, 3, 9, 3], dims=[32, 64, 100, 192],\n",
    "                 global_block=[0, 0, 0, 3], global_block_type=['None', 'None', 'None', 'SDTA'],\n",
    "                 drop_path_rate=0., layer_scale_init_value=1e-6, head_init_scale=1., expan_ratio=4,\n",
    "                 kernel_sizes=[7, 7, 7, 7], heads=[8, 8, 8, 8], use_pos_embd_xca=[False, False, False, False],\n",
    "                 use_pos_embd_global=False, d2_scales=[2, 3, 4, 5], grid_size=5, spline_order=3,\n",
    "                 base_activation=nn.SiLU(), neuron_fun=None, noise_type=None):\n",
    "        super().__init__()\n",
    "        for g in global_block_type:\n",
    "            assert g in ['None', 'SDTA']\n",
    "        if use_pos_embd_global:\n",
    "            self.pos_embd = PositionalEncodingFourier(dim=dims[0])\n",
    "        else:\n",
    "            self.pos_embd = None\n",
    "        self.downsample_layers = nn.ModuleList()  # stem and 3 intermediate downsampling conv layers\n",
    "        stem = nn.Sequential(\n",
    "            nn.Conv2d(in_chans, dims[0], kernel_size=4, stride=4),\n",
    "            LayerNorm(dims[0], eps=1e-6, data_format=\"channels_first\")\n",
    "        )\n",
    "        self.downsample_layers.append(stem)\n",
    "        for i in range(3):\n",
    "            downsample_layer = nn.Sequential(\n",
    "                LayerNorm(dims[i], eps=1e-6, data_format=\"channels_first\"),\n",
    "                nn.Conv2d(dims[i], dims[i + 1], kernel_size=2, stride=2),\n",
    "            )\n",
    "            self.downsample_layers.append(downsample_layer)\n",
    "\n",
    "        self.stages = nn.ModuleList()  # 4 feature resolution stages, each consisting of multiple residual blocks\n",
    "        dp_rates = [x.item() for x in torch.linspace(0, drop_path_rate, sum(depths))]\n",
    "        cur = 0\n",
    "        for i in range(4):\n",
    "            stage_blocks = []\n",
    "            for j in range(depths[i]):\n",
    "                if j > depths[i] - global_block[i] - 1:\n",
    "                    if global_block_type[i] == 'SDTA':\n",
    "                        stage_blocks.append(SDTAEncoder(dim=dims[i], rank_ratio=rank_ratio,drop_path=dp_rates[cur + j],\n",
    "                                                        expan_ratio=expan_ratio, scales=d2_scales[i],\n",
    "                                                        use_pos_emb=use_pos_embd_xca[i], num_heads=heads[i]))\n",
    "                    else:\n",
    "                        raise NotImplementedError\n",
    "                else:\n",
    "                    stage_blocks.append(ConvEncoder(dim=dims[i], rank_ratio=rank_ratio,drop_path=dp_rates[cur + j],\n",
    "                                                    layer_scale_init_value=layer_scale_init_value,\n",
    "                                                    expan_ratio=expan_ratio, kernel_size=kernel_sizes[i]))\n",
    "\n",
    "            self.stages.append(nn.Sequential(*stage_blocks))\n",
    "            cur += depths[i]\n",
    "        self.norm = nn.LayerNorm(dims[-1], eps=1e-6)  # Final norm layer\n",
    "        print(f\"grid_size in EdgeFaceKAN: {grid_size}\")\n",
    "        self.head = KANLinear(dims[-1], num_features,\n",
    "            num=grid_size,\n",
    "            k=spline_order,\n",
    "            base_activation=base_activation,\n",
    "            neuron_fun=neuron_fun,\n",
    "            noise_type=noise_type,\n",
    "        )\n",
    "        self.apply(self._init_weights)\n",
    "\n",
    "    def _init_weights(self, m):\n",
    "        if isinstance(m, nn.Conv2d):\n",
    "            nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "        elif isinstance(m, nn.BatchNorm2d):\n",
    "            nn.init.constant_(m.weight, 1)\n",
    "            nn.init.constant_(m.bias, 0)\n",
    "        elif isinstance(m, nn.LayerNorm):\n",
    "            nn.init.constant_(m.weight, 1)\n",
    "            nn.init.constant_(m.bias, 0)\n",
    "\n",
    "    def forward_features(self, x):\n",
    "        x = self.downsample_layers[0](x)\n",
    "        x = self.stages[0](x)\n",
    "        if self.pos_embd:\n",
    "            B, C, H, W = x.shape\n",
    "            x = x + self.pos_embd(B, H, W)\n",
    "        for i in range(1, 4):\n",
    "            x = self.downsample_layers[i](x)\n",
    "            x = self.stages[i](x)\n",
    "\n",
    "        return self.norm(x.mean([-2, -1]))  # Global average pooling, (N, C, H, W) -> (N, C)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.forward_features(x)\n",
    "        x = self.head(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grid_size in EdgeFaceKAN: 5\n",
      "Noise type: None\n",
      "Neuron fun: None\n",
      "Out dim: : 512\n",
      "In dim:  192\n",
      "Grid size:  5\n",
      "Spline order:  3\n",
      "num: 5, grid_range: [-1, 1]\n",
      "Noise type: None\n",
      "Neuron fun: None\n",
      "Out dim: : 512\n",
      "In dim:  192\n",
      "Grid size:  5\n",
      "Spline order:  3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "EdgeFaceKAN(\n",
       "  (downsample_layers): ModuleList(\n",
       "    (0): Sequential(\n",
       "      (0): Conv2d(3, 32, kernel_size=(4, 4), stride=(4, 4))\n",
       "      (1): LayerNorm()\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): LayerNorm()\n",
       "      (1): Conv2d(32, 64, kernel_size=(2, 2), stride=(2, 2))\n",
       "    )\n",
       "    (2): Sequential(\n",
       "      (0): LayerNorm()\n",
       "      (1): Conv2d(64, 100, kernel_size=(2, 2), stride=(2, 2))\n",
       "    )\n",
       "    (3): Sequential(\n",
       "      (0): LayerNorm()\n",
       "      (1): Conv2d(100, 192, kernel_size=(2, 2), stride=(2, 2))\n",
       "    )\n",
       "  )\n",
       "  (stages): ModuleList(\n",
       "    (0): Sequential(\n",
       "      (0): ConvEncoder(\n",
       "        (dwconv): Conv2d(32, 32, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=32)\n",
       "        (norm): LayerNorm()\n",
       "        (pwconv1): LoRaLin(\n",
       "          (linear1): Linear(in_features=32, out_features=19, bias=False)\n",
       "          (linear2): Linear(in_features=19, out_features=128, bias=True)\n",
       "        )\n",
       "        (act): GELU(approximate='none')\n",
       "        (pwconv2): LoRaLin(\n",
       "          (linear1): Linear(in_features=128, out_features=19, bias=False)\n",
       "          (linear2): Linear(in_features=19, out_features=32, bias=True)\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "      (1): ConvEncoder(\n",
       "        (dwconv): Conv2d(32, 32, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=32)\n",
       "        (norm): LayerNorm()\n",
       "        (pwconv1): LoRaLin(\n",
       "          (linear1): Linear(in_features=32, out_features=19, bias=False)\n",
       "          (linear2): Linear(in_features=19, out_features=128, bias=True)\n",
       "        )\n",
       "        (act): GELU(approximate='none')\n",
       "        (pwconv2): LoRaLin(\n",
       "          (linear1): Linear(in_features=128, out_features=19, bias=False)\n",
       "          (linear2): Linear(in_features=19, out_features=32, bias=True)\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "      (2): ConvEncoder(\n",
       "        (dwconv): Conv2d(32, 32, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=32)\n",
       "        (norm): LayerNorm()\n",
       "        (pwconv1): LoRaLin(\n",
       "          (linear1): Linear(in_features=32, out_features=19, bias=False)\n",
       "          (linear2): Linear(in_features=19, out_features=128, bias=True)\n",
       "        )\n",
       "        (act): GELU(approximate='none')\n",
       "        (pwconv2): LoRaLin(\n",
       "          (linear1): Linear(in_features=128, out_features=19, bias=False)\n",
       "          (linear2): Linear(in_features=19, out_features=32, bias=True)\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): ConvEncoder(\n",
       "        (dwconv): Conv2d(64, 64, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=64)\n",
       "        (norm): LayerNorm()\n",
       "        (pwconv1): LoRaLin(\n",
       "          (linear1): Linear(in_features=64, out_features=38, bias=False)\n",
       "          (linear2): Linear(in_features=38, out_features=256, bias=True)\n",
       "        )\n",
       "        (act): GELU(approximate='none')\n",
       "        (pwconv2): LoRaLin(\n",
       "          (linear1): Linear(in_features=256, out_features=38, bias=False)\n",
       "          (linear2): Linear(in_features=38, out_features=64, bias=True)\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "      (1): ConvEncoder(\n",
       "        (dwconv): Conv2d(64, 64, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=64)\n",
       "        (norm): LayerNorm()\n",
       "        (pwconv1): LoRaLin(\n",
       "          (linear1): Linear(in_features=64, out_features=38, bias=False)\n",
       "          (linear2): Linear(in_features=38, out_features=256, bias=True)\n",
       "        )\n",
       "        (act): GELU(approximate='none')\n",
       "        (pwconv2): LoRaLin(\n",
       "          (linear1): Linear(in_features=256, out_features=38, bias=False)\n",
       "          (linear2): Linear(in_features=38, out_features=64, bias=True)\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "      (2): ConvEncoder(\n",
       "        (dwconv): Conv2d(64, 64, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=64)\n",
       "        (norm): LayerNorm()\n",
       "        (pwconv1): LoRaLin(\n",
       "          (linear1): Linear(in_features=64, out_features=38, bias=False)\n",
       "          (linear2): Linear(in_features=38, out_features=256, bias=True)\n",
       "        )\n",
       "        (act): GELU(approximate='none')\n",
       "        (pwconv2): LoRaLin(\n",
       "          (linear1): Linear(in_features=256, out_features=38, bias=False)\n",
       "          (linear2): Linear(in_features=38, out_features=64, bias=True)\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "    )\n",
       "    (2): Sequential(\n",
       "      (0): ConvEncoder(\n",
       "        (dwconv): Conv2d(100, 100, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=100)\n",
       "        (norm): LayerNorm()\n",
       "        (pwconv1): LoRaLin(\n",
       "          (linear1): Linear(in_features=100, out_features=60, bias=False)\n",
       "          (linear2): Linear(in_features=60, out_features=400, bias=True)\n",
       "        )\n",
       "        (act): GELU(approximate='none')\n",
       "        (pwconv2): LoRaLin(\n",
       "          (linear1): Linear(in_features=400, out_features=60, bias=False)\n",
       "          (linear2): Linear(in_features=60, out_features=100, bias=True)\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "      (1): ConvEncoder(\n",
       "        (dwconv): Conv2d(100, 100, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=100)\n",
       "        (norm): LayerNorm()\n",
       "        (pwconv1): LoRaLin(\n",
       "          (linear1): Linear(in_features=100, out_features=60, bias=False)\n",
       "          (linear2): Linear(in_features=60, out_features=400, bias=True)\n",
       "        )\n",
       "        (act): GELU(approximate='none')\n",
       "        (pwconv2): LoRaLin(\n",
       "          (linear1): Linear(in_features=400, out_features=60, bias=False)\n",
       "          (linear2): Linear(in_features=60, out_features=100, bias=True)\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "      (2): ConvEncoder(\n",
       "        (dwconv): Conv2d(100, 100, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=100)\n",
       "        (norm): LayerNorm()\n",
       "        (pwconv1): LoRaLin(\n",
       "          (linear1): Linear(in_features=100, out_features=60, bias=False)\n",
       "          (linear2): Linear(in_features=60, out_features=400, bias=True)\n",
       "        )\n",
       "        (act): GELU(approximate='none')\n",
       "        (pwconv2): LoRaLin(\n",
       "          (linear1): Linear(in_features=400, out_features=60, bias=False)\n",
       "          (linear2): Linear(in_features=60, out_features=100, bias=True)\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "      (3): ConvEncoder(\n",
       "        (dwconv): Conv2d(100, 100, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=100)\n",
       "        (norm): LayerNorm()\n",
       "        (pwconv1): LoRaLin(\n",
       "          (linear1): Linear(in_features=100, out_features=60, bias=False)\n",
       "          (linear2): Linear(in_features=60, out_features=400, bias=True)\n",
       "        )\n",
       "        (act): GELU(approximate='none')\n",
       "        (pwconv2): LoRaLin(\n",
       "          (linear1): Linear(in_features=400, out_features=60, bias=False)\n",
       "          (linear2): Linear(in_features=60, out_features=100, bias=True)\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "      (4): ConvEncoder(\n",
       "        (dwconv): Conv2d(100, 100, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=100)\n",
       "        (norm): LayerNorm()\n",
       "        (pwconv1): LoRaLin(\n",
       "          (linear1): Linear(in_features=100, out_features=60, bias=False)\n",
       "          (linear2): Linear(in_features=60, out_features=400, bias=True)\n",
       "        )\n",
       "        (act): GELU(approximate='none')\n",
       "        (pwconv2): LoRaLin(\n",
       "          (linear1): Linear(in_features=400, out_features=60, bias=False)\n",
       "          (linear2): Linear(in_features=60, out_features=100, bias=True)\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "      (5): ConvEncoder(\n",
       "        (dwconv): Conv2d(100, 100, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=100)\n",
       "        (norm): LayerNorm()\n",
       "        (pwconv1): LoRaLin(\n",
       "          (linear1): Linear(in_features=100, out_features=60, bias=False)\n",
       "          (linear2): Linear(in_features=60, out_features=400, bias=True)\n",
       "        )\n",
       "        (act): GELU(approximate='none')\n",
       "        (pwconv2): LoRaLin(\n",
       "          (linear1): Linear(in_features=400, out_features=60, bias=False)\n",
       "          (linear2): Linear(in_features=60, out_features=100, bias=True)\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "      (6): ConvEncoder(\n",
       "        (dwconv): Conv2d(100, 100, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=100)\n",
       "        (norm): LayerNorm()\n",
       "        (pwconv1): LoRaLin(\n",
       "          (linear1): Linear(in_features=100, out_features=60, bias=False)\n",
       "          (linear2): Linear(in_features=60, out_features=400, bias=True)\n",
       "        )\n",
       "        (act): GELU(approximate='none')\n",
       "        (pwconv2): LoRaLin(\n",
       "          (linear1): Linear(in_features=400, out_features=60, bias=False)\n",
       "          (linear2): Linear(in_features=60, out_features=100, bias=True)\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "      (7): ConvEncoder(\n",
       "        (dwconv): Conv2d(100, 100, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=100)\n",
       "        (norm): LayerNorm()\n",
       "        (pwconv1): LoRaLin(\n",
       "          (linear1): Linear(in_features=100, out_features=60, bias=False)\n",
       "          (linear2): Linear(in_features=60, out_features=400, bias=True)\n",
       "        )\n",
       "        (act): GELU(approximate='none')\n",
       "        (pwconv2): LoRaLin(\n",
       "          (linear1): Linear(in_features=400, out_features=60, bias=False)\n",
       "          (linear2): Linear(in_features=60, out_features=100, bias=True)\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "      (8): ConvEncoder(\n",
       "        (dwconv): Conv2d(100, 100, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=100)\n",
       "        (norm): LayerNorm()\n",
       "        (pwconv1): LoRaLin(\n",
       "          (linear1): Linear(in_features=100, out_features=60, bias=False)\n",
       "          (linear2): Linear(in_features=60, out_features=400, bias=True)\n",
       "        )\n",
       "        (act): GELU(approximate='none')\n",
       "        (pwconv2): LoRaLin(\n",
       "          (linear1): Linear(in_features=400, out_features=60, bias=False)\n",
       "          (linear2): Linear(in_features=60, out_features=100, bias=True)\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "    )\n",
       "    (3): Sequential(\n",
       "      (0): SDTAEncoder(\n",
       "        (convs): ModuleList(\n",
       "          (0-3): 4 x Conv2d(39, 39, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=39)\n",
       "        )\n",
       "        (norm_xca): LayerNorm()\n",
       "        (xca): XCA(\n",
       "          (qkv): LoRaLin(\n",
       "            (linear1): Linear(in_features=192, out_features=115, bias=False)\n",
       "            (linear2): Linear(in_features=115, out_features=576, bias=False)\n",
       "          )\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): LoRaLin(\n",
       "            (linear1): Linear(in_features=192, out_features=115, bias=False)\n",
       "            (linear2): Linear(in_features=115, out_features=192, bias=True)\n",
       "          )\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (norm): LayerNorm()\n",
       "        (pwconv1): LoRaLin(\n",
       "          (linear1): Linear(in_features=192, out_features=115, bias=False)\n",
       "          (linear2): Linear(in_features=115, out_features=768, bias=True)\n",
       "        )\n",
       "        (act): GELU(approximate='none')\n",
       "        (pwconv2): LoRaLin(\n",
       "          (linear1): Linear(in_features=768, out_features=115, bias=False)\n",
       "          (linear2): Linear(in_features=115, out_features=192, bias=True)\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "      (1): SDTAEncoder(\n",
       "        (convs): ModuleList(\n",
       "          (0-3): 4 x Conv2d(39, 39, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=39)\n",
       "        )\n",
       "        (norm_xca): LayerNorm()\n",
       "        (xca): XCA(\n",
       "          (qkv): LoRaLin(\n",
       "            (linear1): Linear(in_features=192, out_features=115, bias=False)\n",
       "            (linear2): Linear(in_features=115, out_features=576, bias=False)\n",
       "          )\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): LoRaLin(\n",
       "            (linear1): Linear(in_features=192, out_features=115, bias=False)\n",
       "            (linear2): Linear(in_features=115, out_features=192, bias=True)\n",
       "          )\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (norm): LayerNorm()\n",
       "        (pwconv1): LoRaLin(\n",
       "          (linear1): Linear(in_features=192, out_features=115, bias=False)\n",
       "          (linear2): Linear(in_features=115, out_features=768, bias=True)\n",
       "        )\n",
       "        (act): GELU(approximate='none')\n",
       "        (pwconv2): LoRaLin(\n",
       "          (linear1): Linear(in_features=768, out_features=115, bias=False)\n",
       "          (linear2): Linear(in_features=115, out_features=192, bias=True)\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "      (2): SDTAEncoder(\n",
       "        (convs): ModuleList(\n",
       "          (0-3): 4 x Conv2d(39, 39, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=39)\n",
       "        )\n",
       "        (norm_xca): LayerNorm()\n",
       "        (xca): XCA(\n",
       "          (qkv): LoRaLin(\n",
       "            (linear1): Linear(in_features=192, out_features=115, bias=False)\n",
       "            (linear2): Linear(in_features=115, out_features=576, bias=False)\n",
       "          )\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): LoRaLin(\n",
       "            (linear1): Linear(in_features=192, out_features=115, bias=False)\n",
       "            (linear2): Linear(in_features=115, out_features=192, bias=True)\n",
       "          )\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (norm): LayerNorm()\n",
       "        (pwconv1): LoRaLin(\n",
       "          (linear1): Linear(in_features=192, out_features=115, bias=False)\n",
       "          (linear2): Linear(in_features=115, out_features=768, bias=True)\n",
       "        )\n",
       "        (act): GELU(approximate='none')\n",
       "        (pwconv2): LoRaLin(\n",
       "          (linear1): Linear(in_features=768, out_features=115, bias=False)\n",
       "          (linear2): Linear(in_features=115, out_features=192, bias=True)\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (norm): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
       "  (head): KANLinear(\n",
       "    (base_activation): SiLU()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = EdgeFaceKAN(num_features=512, grid_size=5)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "FLOPs_MAP = {\n",
    "    \"zero\": 0,\n",
    "    \"identity\": 0,\n",
    "    \"relu\": 1,\n",
    "    'square_relu': 2,\n",
    "    \"sigmoid\":4,\n",
    "    \"silu\":5,\n",
    "    \"tanh\":6,\n",
    "    \"gelu\": 14,\n",
    "    \"polynomial2\": 1+2+3-1,\n",
    "    \"polynomial3\": 1+2+3+4-1,\n",
    "    \"polynomial5\": 1+2+3+4+5-1,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomIdentity(nn.Module):\n",
    "    def __init__(self, in_dim=None, out_dim=None):\n",
    "        super(CustomIdentity, self).__init__()\n",
    "        self.in_dim = in_dim\n",
    "        self.out_dim = out_dim\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x  # Pass through the input without modification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelWithoutKANLinear(nn.Module):\n",
    "    def __init__(self, model):\n",
    "        super(ModelWithoutKANLinear, self).__init__()\n",
    "        # Create a deepcopy of the model\n",
    "        self.model = deepcopy(model)\n",
    "        # Replace all KANLinear layers with CustomIdentity\n",
    "        for name, module in list(self.model.named_modules()):  # Use list() to avoid size modification issues\n",
    "            if isinstance(module, KANLinear):\n",
    "                # Create a CustomIdentity layer with the same in_features and out_features\n",
    "                custom_identity = CustomIdentity(in_dim=module.in_dim, out_dim=module.out_dim)\n",
    "                # Locate the parent module and replace the KANLinear layer\n",
    "                parent_module, attr_name = self._find_parent_module(name)\n",
    "                if parent_module is not None:\n",
    "                    setattr(parent_module, attr_name, custom_identity)\n",
    "\n",
    "    def _find_parent_module(self, module_name):\n",
    "        \"\"\"\n",
    "        Find the parent module and the attribute name corresponding to `module_name`.\n",
    "        \"\"\"\n",
    "        names = module_name.split('.')\n",
    "        parent = self.model\n",
    "        for name in names[:-1]:\n",
    "            parent = getattr(parent, name, None)\n",
    "            if parent is None:\n",
    "                return None, None\n",
    "        return parent, names[-1]\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ModelWithoutKANLinear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_kan_linear_hook(module, input, output):\n",
    "    # Extract input and output dimensions of the KANLinear layer\n",
    "    din = input[0].shape[1]  # Input size (features in the input tensor)\n",
    "    dout = output.shape[1]  # Output size (features in the output tensor)\n",
    "    grid_size = module.num  # Grid size defined in KANLinear\n",
    "    spline_order = module.k  # Spline order defined in KANLinear\n",
    "\n",
    "    print(f\"din: {din}, dout: {dout}, grid_size: {grid_size}, spline_order: {spline_order}\")\n",
    "\n",
    "    # Automatically calculate FLOPs and Parameters for KANLinear\n",
    "    custom_flops = layer_flops(din, dout, shortcut_name=\"silu\", grid=grid_size, k=spline_order)\n",
    "    custom_params = layer_parameters(din, dout, shortcut_name=\"silu\", grid=grid_size, k=spline_order)\n",
    "    # Store custom FLOPs and Parameters as an attribute on the module\n",
    "    module.__custom_flops__ = custom_flops\n",
    "    module.__custom_params__ = custom_params\n",
    "\n",
    "    # We return the output without modifying it\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def register_kan_linear_hooks(model):\n",
    "    for name, module in model.named_modules():\n",
    "        if isinstance(module, KANLinear):\n",
    "            module.register_forward_hook(custom_kan_linear_hook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def layer_flops(din, dout, shortcut_name=\"silu\", grid=5, k=3):\n",
    "    \"\"\"\n",
    "    Custom FLOPs calculation for KANLinear.\n",
    "    Args:\n",
    "        din (int): Input dimensions.\n",
    "        dout (int): Output dimensions.\n",
    "        shortcut_name (str): Name of the shortcut activation. Default is \"silu\".\n",
    "        grid (int): Grid size parameter.\n",
    "        k (int): Spline order parameter.\n",
    "    Returns:\n",
    "        int: Calculated FLOPs for KANLinear.\n",
    "    \"\"\"\n",
    "    flops = (din * dout) * (9 * k * (grid + 1.5 * k) + 2 * grid - 2.5 * k + 1)\n",
    "    \n",
    "    # Shortcut FLOPs\n",
    "    if shortcut_name == \"zero\":\n",
    "        shortcut_flops = 0\n",
    "    else:\n",
    "        shortcut_flops = FLOPs_MAP[shortcut_name] * din + 2 * din * dout\n",
    "    \n",
    "    return flops + shortcut_flops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def layer_parameters(din, dout, shortcut_name=\"silu\", grid=5, k=3):\n",
    "    \"\"\"\n",
    "    Custom Parameters calculation for KANLinear.\n",
    "    Args:\n",
    "        din (int): Input dimensions.\n",
    "        dout (int): Output dimensions.\n",
    "        shortcut_name (str): Name of the shortcut activation. Default is \"silu\".\n",
    "        grid (int): Grid size parameter.\n",
    "        k (int): Spline order parameter.\n",
    "    Returns:\n",
    "        int: Calculated Parameters for KANLinear.\n",
    "    \"\"\"\n",
    "    parameters = din * dout * (grid + k + 2) + dout\n",
    "    if shortcut_name == \"zero\":\n",
    "        shortcut_parameters = 0\n",
    "    else:\n",
    "        shortcut_parameters = din * dout\n",
    "    return parameters + shortcut_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def info(grid_size=15, neuron_fun=\"mean\", num_features=128, noise_type=None):\n",
    "    # Load the model\n",
    "    net = EdgeFaceKAN(grid_size=grid_size, neuron_fun=neuron_fun, num_features=num_features, noise_type=noise_type)\n",
    "    # Step 1: Compute Base FLOPs (excluding KANLinear)\n",
    "    net_without_kan = ModelWithoutKANLinear(net)\n",
    "    macs, params = get_model_complexity_info(\n",
    "        net_without_kan, (3, 112, 112), backend='pytorch', as_strings=False,\n",
    "        print_per_layer_stat=False, verbose=True\n",
    "    )\n",
    "    base_flops = int(macs) * 2\n",
    "    base_params = int(params)\n",
    "\n",
    "    # Step 2: Register the custom hooks to KANLinear layers\n",
    "    register_kan_linear_hooks(net)\n",
    "\n",
    "    # Step 3: Calculate Total FLOPs (including custom KANLinear FLOPs)\n",
    "    macs, params = get_model_complexity_info(\n",
    "        net, (3, 112, 112), backend='pytorch', as_strings=False,\n",
    "        print_per_layer_stat=False, verbose=True\n",
    "    )\n",
    "\n",
    "    total_flops = base_flops\n",
    "    total_params = base_params\n",
    "    for name, module in net.named_modules():\n",
    "        if isinstance(module, KANLinear):\n",
    "            total_flops += getattr(module, \"__custom_flops__\", 0)  # Add custom FLOPs from hook\n",
    "            total_params += getattr(module, \"__custom_params__\", 0)  # Add custom Parameters from hook\n",
    "\n",
    "    # Step 4: Print Results\n",
    "    print(f\"Base FLOPs (excluding KANLinear): {base_flops} FLOPs\")\n",
    "    print(f\"KANLinear FLOPs: {total_flops - base_flops} FLOPs\")\n",
    "    print(f\"Total FLOPs (with custom KANLinear FLOPs): {total_flops} FLOPs\")\n",
    "    print(f\"Base Parameters (excluding KANLinear): {base_params} Parameters\")\n",
    "    print(f\"KANLinear Parameters: {total_params - base_params} Parameters\")\n",
    "    print(f\"Total Parameters (with custom KANLinear Parameters): {total_params} Parameters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grid_size in EdgeFaceKAN: 5\n",
      "Noise type: None\n",
      "Neuron fun: mean\n",
      "Out dim: : 128\n",
      "In dim:  192\n",
      "Grid size:  5\n",
      "Spline order:  3\n",
      "num: 5, grid_range: [-1, 1]\n",
      "Noise type: None\n",
      "Neuron fun: mean\n",
      "Out dim: : 128\n",
      "In dim:  192\n",
      "Grid size:  5\n",
      "Spline order:  3\n",
      "Warning: module LayerNorm is treated as a zero-op.\n",
      "Warning: module LoRaLin is treated as a zero-op.\n",
      "Warning: module Identity is treated as a zero-op.\n",
      "Warning: module ConvEncoder is treated as a zero-op.\n",
      "Warning: module Dropout is treated as a zero-op.\n",
      "Warning: module XCA is treated as a zero-op.\n",
      "Warning: module SDTAEncoder is treated as a zero-op.\n",
      "Warning: module CustomIdentity is treated as a zero-op.\n",
      "Warning: module EdgeFaceKAN is treated as a zero-op.\n",
      "Warning: module ModelWithoutKANLinear is treated as a zero-op.\n",
      "Warning: module LayerNorm is treated as a zero-op.\n",
      "Warning: module LoRaLin is treated as a zero-op.\n",
      "Warning: module Identity is treated as a zero-op.\n",
      "Warning: module ConvEncoder is treated as a zero-op.\n",
      "Warning: module Dropout is treated as a zero-op.\n",
      "Warning: module XCA is treated as a zero-op.\n",
      "Warning: module SDTAEncoder is treated as a zero-op.\n",
      "Warning: module SiLU is treated as a zero-op.\n",
      "Warning: module KANLinear is treated as a zero-op.\n",
      "Warning: module EdgeFaceKAN is treated as a zero-op.\n",
      "din: 192, dout: 128, grid_size: 5, spline_order: 3\n",
      "Base FLOPs (excluding KANLinear): 158808464 FLOPs\n",
      "KANLinear FLOPs: 6439872.0 FLOPs\n",
      "Total FLOPs (with custom KANLinear FLOPs): 165248336.0 FLOPs\n",
      "Base Parameters (excluding KANLinear): 1884916 Parameters\n",
      "KANLinear Parameters: 270464 Parameters\n",
      "Total Parameters (with custom KANLinear Parameters): 2155380 Parameters\n"
     ]
    }
   ],
   "source": [
    "info(grid_size=5, neuron_fun=\"mean\", num_features=128, noise_type=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grid_size in EdgeFaceKAN: 5\n",
      "Noise type: None\n",
      "Neuron fun: mean\n",
      "Out dim: : 128\n",
      "In dim:  192\n",
      "Grid size:  5\n",
      "Spline order:  3\n",
      "num: 5, grid_range: [-1, 1]\n",
      "Noise type: None\n",
      "Neuron fun: mean\n",
      "Out dim: : 128\n",
      "In dim:  192\n",
      "Grid size:  5\n",
      "Spline order:  3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "===============================================================================================\n",
       "Layer (type:depth-idx)                        Output Shape              Param #\n",
       "===============================================================================================\n",
       "EdgeFaceKAN                                   [1, 128]                  --\n",
       "├─ModuleList: 1-7                             --                        (recursive)\n",
       "│    └─Sequential: 2-1                        [1, 32, 28, 28]           --\n",
       "│    │    └─Conv2d: 3-1                       [1, 32, 28, 28]           1,568\n",
       "│    │    └─LayerNorm: 3-2                    [1, 32, 28, 28]           64\n",
       "├─ModuleList: 1-8                             --                        (recursive)\n",
       "│    └─Sequential: 2-2                        [1, 32, 28, 28]           --\n",
       "│    │    └─ConvEncoder: 3-3                  [1, 32, 28, 28]           7,936\n",
       "│    │    └─ConvEncoder: 3-4                  [1, 32, 28, 28]           7,936\n",
       "│    │    └─ConvEncoder: 3-5                  [1, 32, 28, 28]           7,936\n",
       "├─ModuleList: 1-7                             --                        (recursive)\n",
       "│    └─Sequential: 2-3                        [1, 64, 14, 14]           --\n",
       "│    │    └─LayerNorm: 3-6                    [1, 32, 28, 28]           64\n",
       "│    │    └─Conv2d: 3-7                       [1, 64, 14, 14]           8,256\n",
       "├─ModuleList: 1-8                             --                        (recursive)\n",
       "│    └─Sequential: 2-4                        [1, 64, 14, 14]           --\n",
       "│    │    └─ConvEncoder: 3-8                  [1, 64, 14, 14]           28,032\n",
       "│    │    └─ConvEncoder: 3-9                  [1, 64, 14, 14]           28,032\n",
       "│    │    └─ConvEncoder: 3-10                 [1, 64, 14, 14]           28,032\n",
       "├─ModuleList: 1-7                             --                        (recursive)\n",
       "│    └─Sequential: 2-5                        [1, 100, 7, 7]            --\n",
       "│    │    └─LayerNorm: 3-11                   [1, 64, 14, 14]           128\n",
       "│    │    └─Conv2d: 3-12                      [1, 100, 7, 7]            25,700\n",
       "├─ModuleList: 1-8                             --                        (recursive)\n",
       "│    └─Sequential: 2-6                        [1, 100, 7, 7]            --\n",
       "│    │    └─ConvEncoder: 3-13                 [1, 100, 7, 7]            65,800\n",
       "│    │    └─ConvEncoder: 3-14                 [1, 100, 7, 7]            65,800\n",
       "│    │    └─ConvEncoder: 3-15                 [1, 100, 7, 7]            65,800\n",
       "│    │    └─ConvEncoder: 3-16                 [1, 100, 7, 7]            65,800\n",
       "│    │    └─ConvEncoder: 3-17                 [1, 100, 7, 7]            65,800\n",
       "│    │    └─ConvEncoder: 3-18                 [1, 100, 7, 7]            65,800\n",
       "│    │    └─ConvEncoder: 3-19                 [1, 100, 7, 7]            65,800\n",
       "│    │    └─ConvEncoder: 3-20                 [1, 100, 7, 7]            65,800\n",
       "│    │    └─ConvEncoder: 3-21                 [1, 100, 7, 7]            65,800\n",
       "├─ModuleList: 1-7                             --                        (recursive)\n",
       "│    └─Sequential: 2-7                        [1, 192, 3, 3]            --\n",
       "│    │    └─LayerNorm: 3-22                   [1, 100, 7, 7]            200\n",
       "│    │    └─Conv2d: 3-23                      [1, 192, 3, 3]            76,992\n",
       "├─ModuleList: 1-8                             --                        (recursive)\n",
       "│    └─Sequential: 2-8                        [1, 192, 3, 3]            --\n",
       "│    │    └─SDTAEncoder: 3-24                 [1, 192, 3, 3]            357,152\n",
       "│    │    └─SDTAEncoder: 3-25                 [1, 192, 3, 3]            357,152\n",
       "│    │    └─SDTAEncoder: 3-26                 [1, 192, 3, 3]            357,152\n",
       "├─LayerNorm: 1-9                              [1, 192]                  384\n",
       "├─KANLinear: 1-10                             [1, 128]                  248,065\n",
       "│    └─SiLU: 2-9                              [1, 192]                  --\n",
       "===============================================================================================\n",
       "Total params: 2,132,981\n",
       "Trainable params: 2,130,677\n",
       "Non-trainable params: 2,304\n",
       "Total mult-adds (M): 14.40\n",
       "===============================================================================================\n",
       "Input size (MB): 0.15\n",
       "Forward/backward pass size (MB): 11.77\n",
       "Params size (MB): 7.53\n",
       "Estimated Total Size (MB): 19.45\n",
       "==============================================================================================="
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchinfo import summary\n",
    "\n",
    "model = EdgeFaceKAN(grid_size=5, neuron_fun=\"mean\", num_features=128, noise_type=None)\n",
    "summary(model, input_size=(1, 3, 112, 112))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "info() got an unexpected keyword argument 'num'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43minfo\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m128\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrid\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnoise\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: info() got an unexpected keyword argument 'num'"
     ]
    }
   ],
   "source": [
    "info(num=128, grid=10, noise=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "capstone",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
